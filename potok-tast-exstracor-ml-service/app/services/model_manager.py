import torch
import pickle
import json
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime
import shutil

from app.config.settings import get_settings
from app.utils.logger import setup_logger
from app.utils.exceptions import ModelNotLoadedException, ModelNotTrainedException
from app.core.models import StatusNet
from app.core.vocabulary import Vocabulary

settings = get_settings()
logger = setup_logger("model_manager", settings.LOG_LEVEL)

class ModelManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏ - –∑–∞–≥—Ä—É–∑–∫–∞, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    
    def __init__(self):
        self.models_dir = Path(settings.MODEL_DIR)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.current_model: Optional[StatusNet] = None
        self.current_vocab: Optional[Vocabulary] = None
        self.current_encoders: Optional[Dict] = None
        self.current_version: Optional[str] = None
    
    def save_model(
        self,
        model: StatusNet,
        vocab: Vocabulary,
        encoders: Dict,
        model_name: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        
        Args:
            model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            vocab: –°–ª–æ–≤–∞—Ä—å
            encoders: –≠–Ω–∫–æ–¥–µ—Ä—ã
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –í–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        version = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_path = self.models_dir / model_name / version
        model_path.mkdir(parents=True, exist_ok=True)
        
        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
            torch.save(model.state_dict(), model_path / "model.pth")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è
            with open(model_path / "vocab.pkl", 'wb') as f:
                pickle.dump(vocab, f)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
            with open(model_path / "encoders.pkl", 'wb') as f:
                pickle.dump(encoders, f)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata_full = {
                "model_name": model_name,
                "version": version,
                "saved_at": datetime.utcnow().isoformat(),
                "vocab_size": vocab.vocab_size,
                "device": settings.DEVICE,
                **(metadata or {})
            }
            
            with open(model_path / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata_full, f, indent=2, ensure_ascii=False)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–ª–∏–Ω–∫–∞ –Ω–∞ latest
            latest_link = self.models_dir / model_name / "latest"
            if latest_link.exists():
                latest_link.unlink()
            latest_link.symlink_to(version)
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_name}/{version}")
            return version
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            # –û—Ç–∫–∞—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if model_path.exists():
                shutil.rmtree(model_path)
            raise
    
    def load_model(
        self,
        model_name: str,
        version: Optional[str] = None,
        device: Optional[str] = None
    ) -> tuple[StatusNet, Vocabulary, Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        
        Args:
            model_name: –ò–º—è –º–æ–¥–µ–ª–∏
            version: –í–µ—Ä—Å–∏—è (–µ—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è latest)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu/cuda)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (model, vocab, encoders)
        """
        if device is None:
            device = settings.DEVICE
        
        if version is None:
            model_path = self.models_dir / model_name / "latest"
        else:
            model_path = self.models_dir / model_name / version
        
        if not model_path.exists():
            raise ModelNotLoadedException(
                f"–ú–æ–¥–µ–ª—å {model_name}/{version or 'latest'} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            )
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            with open(model_path / "metadata.json", 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è
            with open(model_path / "vocab.pkl", 'rb') as f:
                vocab = pickle.load(f)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
            with open(model_path / "encoders.pkl", 'rb') as f:
                encoders = pickle.load(f)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            model = StatusNet(
                vocab_size=vocab.vocab_size,
                embedding_dim=settings.EMBEDDING_DIM,
                hidden_dim=settings.HIDDEN_DIM,
                num_statuses=encoders['status'].num_classes
            ).to(device)
            
            model.load_state_dict(
                torch.load(model_path / "model.pth", map_location=device)
            )
            model.eval()
            
            self.current_model = model
            self.current_vocab = vocab
            self.current_encoders = encoders
            self.current_version = metadata['version']
            
            logger.info(
                f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_name}/{metadata['version']}"
            )
            
            return model, vocab, encoders
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise ModelNotLoadedException(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
    
    def list_models(self) -> Dict[str, list]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        models = {}
        
        for model_dir in self.models_dir.iterdir():
            if not model_dir.is_dir():
                continue
            
            versions = []
            for version_dir in model_dir.iterdir():
                if version_dir.is_dir() and version_dir.name != "latest":
                    metadata_file = version_dir / "metadata.json"
                    if metadata_file.exists():
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        versions.append(metadata)
            
            if versions:
                models[model_dir.name] = sorted(
                    versions,
                    key=lambda x: x['saved_at'],
                    reverse=True
                )
        
        return models
    
    def delete_model(self, model_name: str, version: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏"""
        model_path = self.models_dir / model_name / version
        
        if not model_path.exists():
            logger.warning(f"–ú–æ–¥–µ–ª—å {model_name}/{version} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False
        
        try:
            shutil.rmtree(model_path)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}/{version}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def get_current_model_info(self) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if self.current_model is None:
            return None
        
        return {
            "version": self.current_version,
            "vocab_size": self.current_vocab.vocab_size if self.current_vocab else 0,
            "is_training": self.current_model.training,
            "device": next(self.current_model.parameters()).device.type
        }
